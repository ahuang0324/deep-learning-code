{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed294247-bdf7-4bc4-8c50-9d2bb6adc14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff03c175-4dc0-4d2f-996e-06b97bfe8d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\python39.zip',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\DLLs',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\lib',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39',\n",
       " '',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\lib\\\\site-packages',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\lib\\\\site-packages\\\\win32',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'D:\\\\Anaconda\\\\envs\\\\learn_pytorch_39\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1019391d-b2fe-4198-b8a0-40abed4a5d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cu126'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef92502-4d6b-4832-88ce-a9eec25a6c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2419a2-95e3-417b-a5ce-9e78e36d0a8b",
   "metadata": {},
   "source": [
    "### pytorch 里面没有类型支持string\n",
    "所以对于 NLP 会使用Embedding 的一些向量库 如 word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4821f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.LongTensor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(1)\n",
    "b = torch.tensor(1.)\n",
    "print(b.type())\n",
    "print(a.type())\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9fd6d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.cuda()\n",
    "isinstance(a,torch.cuda.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a36e1",
   "metadata": {},
   "source": [
    "dimension = 0 的tensor 一般用来表示loss\n",
    "dimension = 1 的就是向量或者标量，在python里面就是一维数组 一般用来表示神经网络中的bias\n",
    "创建方法：\n",
    "- 从列表创建  torch.tensor([1,2,3,4])\n",
    "- 从类型创建 给出维度 torch.FloatTensor(2)\n",
    "- 从numpy 引入 torch.from_numpy(data)\n",
    "- 随机初始化\n",
    "  - torch.rand(size) 创建[0,1) 的随机取值\n",
    "  - torch.rand_like(tensor) 接受的参数是一个tensor变量 形状和tensor的一样\n",
    "  - torch.randn(size) 创建的是 均值为0 方差为1 的正态分布 常用于各种权重的初始化\n",
    "  - torch.randint(min,max,shape) [min,max) 整数\n",
    "- 注意 torch.Tensor() 跟 torch.FloatTensor() 作用是一样的，参数都是shape torch.tensor(list) 参数是list\n",
    "- torch.empty(shape) 创建一块内存空间，但是不赋值\n",
    "- torch.arange(start,end,step)  与python 中的range 一样\n",
    "- torch.linspace(start,end,num)  [start,end] num 个数，这里不一样，首先是 end闭区间，其次是 不是步长，而是个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape,a.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22736db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.8824e-21, 1.9212e-42, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(2,3) # 两行三列\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9e73019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = np.ones((2,3))\n",
    "b = torch.from_numpy(b)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "843e3a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.5000,  4.0000,  5.5000,  7.0000,  8.5000, 10.0000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.linspace(1,10,7)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc544954",
   "metadata": {},
   "source": [
    "### 切片和索引\n",
    "- torch.index_select(dim,[])\n",
    "- 多个 :,:,: 可以省略称... \n",
    "- torch.masked_select(tensor,mask)  感觉很像是bool索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1f5db26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4,3,28,28)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bd806c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,2,...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7869c681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b5a06b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9906,  1.5477, -2.0208,  0.9014],\n",
       "        [ 0.2829,  0.1293, -0.6898, -0.5056],\n",
       "        [ 0.9746,  0.8371, -0.8640,  0.3805]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d86a1c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [ True,  True, False, False]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = x.ge(0.5) # 大于\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09791419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9906, 1.5477, 0.9014, 0.9746, 0.8371])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(x,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8f4d3",
   "metadata": {},
   "source": [
    "### 维度变换\n",
    "- View reshape 功能完全相同，直接用reshape 就行\n",
    "- unsqueeze(dim) 在dim 增加一个维度，其他维度向后移动\n",
    "- squeeze() 默认是将为1的维度都去掉 squeeze(dim) 如果shape 不是1 则不会变\n",
    "- expand ： broadcasting 不会立刻复制，只在用到的时候才进行复制\n",
    "- repeat : 直接进行复制（ 都是只有dim = 1 时才会进行复制）（需要不变可以写-1）\n",
    "    - 注意 expand(shape) 参数是扩展后的shape，而repeat() 中的参数是每个维度重复的次数\n",
    "- .t() 转置，只能适用于二维的矩阵\n",
    "- .transpose(dim1,dim2) 用来交换连个维度 \n",
    "    - 注意：使用之后，数据的内存就会变得不连续，就不能使用view(但是可以在前面加上contiguous())  但可以使用reshape\n",
    "- 。permute()  参数就是你想要的之前维度的排列方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24907650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 3, 28, 28]),\n",
       " tensor([[ 1.5289,  0.6486,  0.0149,  ..., -0.7132, -1.4077,  0.0785],\n",
       "         [ 1.0363, -0.7139,  0.6095,  ..., -1.2027, -0.6341, -0.0110],\n",
       "         [ 1.8179, -1.1500, -0.5700,  ...,  0.2262, -0.6996, -0.5316],\n",
       "         [ 1.5854,  0.5165,  0.3571,  ...,  0.4487, -1.2539,  0.7470]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4,3,28,28)\n",
    "a.shape,a.transpose(1,3).contiguous().view(4,3*28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27604e71",
   "metadata": {},
   "source": [
    "### Merge or Split\n",
    "- cat 合并 torch.cat([tensor1,tensor2],dim = ) 要求只有dim 那个维度数字可以不一样，其他必须一样\n",
    "- stack([tensor1,tensor2],dim = ) 要求维度完全相同，然后在dim上添加一个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59789a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 32, 8]), torch.Size([5, 56, 8]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [calss，stuednt，course] 学生成绩单\n",
    "a = torch.randn(4,32,8)\n",
    "b = torch.randn(5,32,8)\n",
    "c = torch.randn(5,24,8)\n",
    "torch.cat([a,b],dim = 0).shape ,torch.cat([c,b],dim = 1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33c58ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 32, 8])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.randn(4,32,8)\n",
    "a2 = torch.randn(4,32,8)\n",
    "torch.stack([a1,a2],dim = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc7f38fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 8]), torch.Size([2, 32, 8]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.rand(3,32,8)\n",
    "a1,a2 = c.split([1,2],dim = 0)\n",
    "a1.shape,a2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871fd07",
   "metadata": {},
   "source": [
    "### tensor 的基本运算\n",
    "- torch.mm() only for 2d\n",
    "- torch.matmul() 矩阵相乘 @ 一样 对于高纬度的矩阵 matmul 还是只取最后两个维度进行运算\n",
    "- torch.exp()\n",
    "- torch.log() log2() log10()\n",
    "- .floor() 向下取整 .ceil() 向上取整 .round() 四舍五入 .trunc()截取数字的整数部分 .frac() 截取数字的小数部分\n",
    "- .clamp(min) .clamp(min,max) 设置一个最小值和最大值 小于min的 都变成min\n",
    "    — 常用在梯度爆炸的时候，给梯度限制一个最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1210773e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5927, 0.7599, 1.1065, 1.0511, 0.4303],\n",
       "        [0.6924, 0.8996, 1.2622, 1.2823, 0.7034],\n",
       "        [0.1371, 0.5106, 0.7409, 0.6820, 0.6451],\n",
       "        [0.7937, 0.8772, 1.2085, 1.2807, 0.6140]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(4,3)\n",
    "b = torch.rand(3,5)\n",
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e216f",
   "metadata": {},
   "source": [
    "### tensor 的统计属性 \n",
    "- 范数 norm 范数是向量或者矩阵大小的度量，将向量映射到非负实数的函数，它可以衡量向量的大小或长度\n",
    "    - torch.nn.functional.normalize 用于对输入张量进行归一化处理，也就是将输入张量的每个元素除以其范数，使得处理后的张量的范数为 1。\n",
    "    - 第一范数是所有元素绝对值求和\n",
    "    - norm = 2 是所有元素平方和再开根号\n",
    "- 也可以在某个维度上求范式 norm(p = ,dim = )\n",
    "- mean() 平均值 sum() min() prod() 累乘\n",
    "- argmax() argmin() 返回的是索引，是最大元素的索引或者最小元素的索引 \n",
    "    - 如果是高维的，且不指定维度，则会打平，\n",
    "    - 指定哪个维度，哪个维度就会被压缩，变成一个值\n",
    "    - 一般可以配合max 一起使用 max(dim = ,keepdim = Trye or False)\n",
    "- topk(num,dim,largest = ) largets = False 表示最小的几个\n",
    "- torch.equal() 只返回一个True or False torch.eq() =  ==\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af2698b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10)\n",
    "b = torch.arange(10)\n",
    "torch.equal(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0bd377",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "- sigmoid函数，也叫logistic 函数，所以这也是logistic regression 的由来\n",
    "- sigmoid函数有一个很特别的性质  \n",
    "$ sigmoid = \\dfrac{1}{1 + e^{-x}} $    \n",
    "$ y' = y(1-y)$   \n",
    "所以求导很快  \n",
    "- 有个问题，就是如果x特别大或者x特别小说，会过于平缓，这就是梯度离散或者梯度消失\n",
    "- 使用方法 import nn.functional as F   F.sigmoid() torch.sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9cecb",
   "metadata": {},
   "source": [
    "- Tanh 激活函数\n",
    "\\begin{align}\n",
    "f(x) = tanh(x) &= \\dfrac{e^x - e^{-x}}{e^x + e^{-x}} \\\\\n",
    "&= 2sigmoid(2x)-1\n",
    "\\end{align}\n",
    "\n",
    "- softmax() 激活函数\n",
    "$ y = \\dfrac{exp(o_i)}{\\sum{}_{k}exp(o_k)} $   \n",
    "softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持 可导的性质  \n",
    "\n",
    "softmax 激活函数会放大差距，而且各个概率的总和为1 特别适合用来分类问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2eea3499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9933)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.sigmoid(torch.tensor(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942be56d",
   "metadata": {},
   "source": [
    "### 损失函数Loss\n",
    "- 均方差 MSE Mean Squared Error\n",
    "- Cross Entropy loss 交叉熵损失函数\n",
    "    - 交叉熵常用来衡量两个概率的区别 如现在有两个概率分布p 和q  \n",
    "    $ H(p,q) = \\sum_{i}-p_{i}log(q_i)$  \n",
    "\n",
    "交叉熵 可以想象为 主观概率为Q 的观察者在看到根据概率P生成的数据时的预期惊讶程度 （主观概率Q 就是Label P就是预测值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53a5d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5779934d",
   "metadata": {},
   "source": [
    "### 自动求导 torch.autograd.grad(output,input) 与 output.backward()\n",
    "- autograd 不会累计梯度，会将梯度的计算结果直接返回 .backward()不会返回梯度，而是累计在.grad里面\n",
    "- torch.autograd.grad(loss,[w1,w2,w3])  loss.backward() w1.grad w2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab54ef",
   "metadata": {},
   "source": [
    "### Visdom 可视化\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_pytorch_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
